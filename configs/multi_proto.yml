all:
  task_trainer: "multi_proto"
  hp:
    use_class_attrs: true
    img_target_shape: [256, 256]
    max_num_epochs: 5
    batch_size: 10

    head:
      type: "multi_headed"
      num_prototypes: 1
      hid_dim: 512
      normalize: true
      scale_value: 10.
      combine_strategy: "mean"
      use_final-activation: false

      logits_scaling: # Scaling by num_prototypes and scale_value
          enabled: false
          scale_value: 1.

      senet:
        enabled: false
        reduction_dim: 16

    # head:
    #   type: "embedding_based"
    #   num_prototypes: 1
    #   hid_dim: 512
    #   normalize: true
    #   scale_value: 10.
    #   combine_strategy: "sum"
    #   context:
    #     type: "random"
    #     # transform_layers: [64]
    #     same_for_each_class: true
    #     std: 1.
    #   fusing_type: "concat"

      # head:
      #   type: "embedding_based"
      #   num_prototypes: 1
      #   hid_dim: 512
      #   normalize: true
      #   scale_value: 10.
      #   combine_strategy: "sum"
      #   context:
      #     type: "static"
      #     proto_emb_size: 512
      #   fusing_type: "concat"

    push_protos_apart:
      enabled: false
      loss_coef: 1

cub:
  hp:
    pretrained: true

awa:
  hp:
    pretrained: false

tiny_imagenet: {}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_binary(n: int, length: int) -> List[int]:\n",
    "    binary = [int(d) for d in bin(n)[2:]]\n",
    "    result = np.zeros(length).astype(np.float32)\n",
    "    result[-len(binary):] = binary\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "class EmbedNumber(nn.Module):\n",
    "    def __init__(self, max_d: int, emb_size: int):\n",
    "        super(EmbedNumber, self).__init__()\n",
    "        \n",
    "        self.max_d = max_d\n",
    "        self.layer = nn.Linear(max_d, emb_size)\n",
    "        \n",
    "    def forward(self, x: Tensor):\n",
    "        x_binary = [convert_to_binary(d, self.max_d) for d in x]\n",
    "        x_binary = torch.tensor(x_binary).to(x.device)\n",
    "        x_binary = (x_binary - x_binary.mean(dim=0, keepdim=True)) / x_binary.std(dim=0, keepdim=True)\n",
    "        \n",
    "        return self.layer(x_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/500 [00:00<03:45,  2.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.19155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 2/500 [00:00<03:35,  2.31it/s]\u001b[A\n",
      "  1%|          | 3/500 [00:01<03:30,  2.36it/s]\u001b[A\n",
      "  1%|          | 4/500 [00:01<03:26,  2.40it/s]\u001b[A\n",
      "  1%|          | 5/500 [00:02<03:23,  2.43it/s]\u001b[A\n",
      "  1%|          | 6/500 [00:02<03:19,  2.47it/s]\u001b[A\n",
      "  1%|▏         | 7/500 [00:02<03:16,  2.51it/s]\u001b[A\n",
      "  2%|▏         | 8/500 [00:03<03:14,  2.53it/s]\u001b[A\n",
      "  2%|▏         | 9/500 [00:03<03:23,  2.41it/s]\u001b[A\n",
      "  2%|▏         | 10/500 [00:04<03:21,  2.43it/s]\u001b[A\n",
      "  2%|▏         | 11/500 [00:04<03:17,  2.47it/s]\u001b[A\n",
      "  2%|▏         | 12/500 [00:04<03:15,  2.50it/s]\u001b[A\n",
      "  3%|▎         | 13/500 [00:05<03:12,  2.53it/s]\u001b[A\n",
      "  3%|▎         | 14/500 [00:05<03:11,  2.54it/s]\u001b[A\n",
      "  3%|▎         | 15/500 [00:06<03:09,  2.55it/s]\u001b[A\n",
      "  3%|▎         | 16/500 [00:06<03:08,  2.56it/s]\u001b[A\n",
      "  3%|▎         | 17/500 [00:06<03:18,  2.43it/s]\u001b[A\n",
      "  4%|▎         | 18/500 [00:07<03:19,  2.41it/s]\u001b[A\n",
      "  4%|▍         | 19/500 [00:07<03:15,  2.46it/s]\u001b[A\n",
      "  4%|▍         | 20/500 [00:08<03:12,  2.50it/s]\u001b[A\n",
      "  4%|▍         | 21/500 [00:08<03:09,  2.52it/s]\u001b[A\n",
      "  4%|▍         | 22/500 [00:08<03:08,  2.54it/s]\u001b[A\n",
      "  5%|▍         | 23/500 [00:09<03:06,  2.55it/s]\u001b[A\n",
      "  5%|▍         | 24/500 [00:09<03:05,  2.56it/s]\u001b[A\n",
      "  5%|▌         | 25/500 [00:09<03:05,  2.56it/s]\u001b[A\n",
      "  5%|▌         | 26/500 [00:10<03:05,  2.56it/s]\u001b[A\n",
      "  5%|▌         | 27/500 [00:10<03:04,  2.56it/s]\u001b[A\n",
      "  6%|▌         | 28/500 [00:11<03:04,  2.56it/s]\u001b[A\n",
      "  6%|▌         | 29/500 [00:11<03:04,  2.55it/s]\u001b[A\n",
      "  6%|▌         | 30/500 [00:11<03:03,  2.56it/s]\u001b[A\n",
      "  6%|▌         | 31/500 [00:12<03:03,  2.55it/s]\u001b[A\n",
      "  6%|▋         | 32/500 [00:12<03:03,  2.55it/s]\u001b[A\n",
      "  7%|▋         | 33/500 [00:13<03:02,  2.55it/s]\u001b[A\n",
      "  7%|▋         | 34/500 [00:13<03:02,  2.56it/s]\u001b[A\n",
      "  7%|▋         | 35/500 [00:13<03:01,  2.56it/s]\u001b[A\n",
      "  7%|▋         | 36/500 [00:14<03:01,  2.56it/s]\u001b[A\n",
      "  7%|▋         | 37/500 [00:14<03:00,  2.56it/s]\u001b[A\n",
      "  8%|▊         | 38/500 [00:15<03:00,  2.56it/s]\u001b[A\n",
      "  8%|▊         | 39/500 [00:15<03:00,  2.56it/s]\u001b[A\n",
      "  8%|▊         | 40/500 [00:15<02:59,  2.56it/s]\u001b[A\n",
      "  8%|▊         | 41/500 [00:16<02:59,  2.56it/s]\u001b[A\n",
      "  8%|▊         | 42/500 [00:16<02:58,  2.56it/s]\u001b[A\n",
      "  9%|▊         | 43/500 [00:17<02:58,  2.56it/s]\u001b[A\n",
      "  9%|▉         | 44/500 [00:17<02:57,  2.57it/s]\u001b[A\n",
      "  9%|▉         | 45/500 [00:17<02:57,  2.57it/s]\u001b[A\n",
      "  9%|▉         | 46/500 [00:18<02:56,  2.57it/s]\u001b[A\n",
      "  9%|▉         | 47/500 [00:18<02:55,  2.57it/s]\u001b[A\n",
      " 10%|▉         | 48/500 [00:18<02:55,  2.57it/s]\u001b[A\n",
      " 10%|▉         | 49/500 [00:19<02:55,  2.57it/s]\u001b[A\n",
      " 10%|█         | 50/500 [00:19<02:55,  2.57it/s]\u001b[A\n",
      " 10%|█         | 51/500 [00:20<02:55,  2.57it/s]\u001b[A\n",
      " 10%|█         | 52/500 [00:20<02:54,  2.56it/s]\u001b[A\n",
      " 11%|█         | 53/500 [00:20<02:54,  2.57it/s]\u001b[A\n",
      " 11%|█         | 54/500 [00:21<02:53,  2.57it/s]\u001b[A\n",
      " 11%|█         | 55/500 [00:21<02:53,  2.57it/s]\u001b[A\n",
      " 11%|█         | 56/500 [00:22<02:52,  2.57it/s]\u001b[A\n",
      " 11%|█▏        | 57/500 [00:22<02:52,  2.57it/s]\u001b[A\n",
      " 12%|█▏        | 58/500 [00:22<02:51,  2.58it/s]\u001b[A\n",
      " 12%|█▏        | 59/500 [00:23<02:51,  2.58it/s]\u001b[A\n",
      " 12%|█▏        | 60/500 [00:23<02:51,  2.57it/s]\u001b[A\n",
      " 12%|█▏        | 61/500 [00:24<02:50,  2.58it/s]\u001b[A\n",
      " 12%|█▏        | 62/500 [00:24<02:49,  2.58it/s]\u001b[A\n",
      " 13%|█▎        | 63/500 [00:24<02:49,  2.59it/s]\u001b[A\n",
      " 13%|█▎        | 64/500 [00:25<02:47,  2.60it/s]\u001b[A\n",
      " 13%|█▎        | 65/500 [00:25<02:47,  2.59it/s]\u001b[A\n",
      " 13%|█▎        | 66/500 [00:25<02:48,  2.58it/s]\u001b[A\n",
      " 13%|█▎        | 67/500 [00:26<02:47,  2.58it/s]\u001b[A\n",
      " 14%|█▎        | 68/500 [00:26<02:47,  2.57it/s]\u001b[A\n",
      " 14%|█▍        | 69/500 [00:27<02:47,  2.57it/s]\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-46c23714da5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_num_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumbers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-daa55ff8a12e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mx_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconvert_to_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_d\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mx_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_binary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_binary\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx_binary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mx_binary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-daa55ff8a12e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mx_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconvert_to_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_d\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mx_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_binary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_binary\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx_binary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mx_binary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-46c23714da5f>\u001b[0m in \u001b[0;36mconvert_to_binary\u001b[0;34m(n, length)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#     result[-len(binary):] = binary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_codes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m model = nn.Sequential(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "ds_size = 10000\n",
    "z_dim = 16\n",
    "dataset = torch.randn(ds_size, z_dim).to(DEVICE)\n",
    "numbers = torch.arange(ds_size).to(DEVICE)\n",
    "max_num_iters = 500\n",
    "emb_size = 2048\n",
    "max_d = 32\n",
    "hid_size = 512\n",
    "\n",
    "binary_codes = (torch.rand(ds_size, 32) > 0.5).float().numpy()\n",
    "\n",
    "\n",
    "def convert_to_binary(n: int, length: int) -> List[int]:\n",
    "#     binary = [int(d) for d in bin(n)[2:]]\n",
    "#     result = np.zeros(length).astype(np.float32)\n",
    "#     result[-len(binary):] = binary\n",
    "    \n",
    "    return binary_codes[n]\n",
    "\n",
    "model = nn.Sequential(\n",
    "    EmbedNumber(max_d, emb_size),\n",
    "    nn.BatchNorm1d(emb_size),\n",
    "    nn.ReLU(),\n",
    "    \n",
    "    nn.Linear(emb_size, hid_size),\n",
    "    nn.BatchNorm1d(hid_size),\n",
    "    nn.ReLU(),\n",
    "    \n",
    "    nn.Linear(hid_size, hid_size),\n",
    "    nn.BatchNorm1d(hid_size),\n",
    "    nn.ReLU(),\n",
    "    \n",
    "    nn.Linear(hid_size, hid_size),\n",
    "    nn.BatchNorm1d(hid_size),\n",
    "    nn.ReLU(),\n",
    "    \n",
    "    nn.Linear(hid_size, hid_size),\n",
    "    nn.BatchNorm1d(hid_size),\n",
    "    nn.ReLU(),\n",
    "    \n",
    "    nn.Linear(hid_size, z_dim)\n",
    ")\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, factor=0.2, patience=50, threshold=0.005, verbose=True)\n",
    "\n",
    "for i in tqdm(range(max_num_iters)):\n",
    "    preds = model(numbers)\n",
    "    loss = F.mse_loss(preds, dataset)\n",
    "\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    \n",
    "    scheduler.step(loss)\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(f'Loss: {loss.item():.05f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:02<40:59,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9995099902153015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 101/1000 [07:30<1:31:48,  6.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6497169137001038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 201/1000 [17:56<1:24:49,  6.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.11679525673389435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 301/1000 [29:02<1:01:58,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.016076019033789635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 401/1000 [39:25<1:06:23,  6.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0030346722342073917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 501/1000 [50:18<52:05,  6.26s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0013863989152014256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 601/1000 [1:00:39<38:49,  5.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0006943172193132341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 672/1000 [1:07:29<30:02,  5.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   671: reducing learning rate of group 0 to 2.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 701/1000 [1:10:16<29:23,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.00021488837955985218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 801/1000 [1:19:45<19:08,  5.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.00019937483011744916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 901/1000 [1:29:20<09:14,  5.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.00019017573504243046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [1:38:50<00:00,  5.93s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "ds_size = 10000\n",
    "z_dim = 32\n",
    "hid_size = 2048\n",
    "dataset = torch.randn(ds_size, z_dim).to(DEVICE)\n",
    "max_num_iters = 1000\n",
    "\n",
    "model = nn.LSTM(z_dim, hid_size, num_layers=1, batch_first=True)\n",
    "output = nn.Sequential(\n",
    "    nn.Linear(hid_size, z_dim),\n",
    ").to(DEVICE)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "optim = torch.optim.Adam(list(model.parameters()) + list(output.parameters()), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, factor=0.2, patience=50, threshold=0.005, verbose=True)\n",
    "\n",
    "inputs = torch.cat([torch.zeros(1, z_dim).to(DEVICE), dataset])\n",
    "targets = torch.cat([dataset, torch.zeros(1, z_dim).to(DEVICE)])\n",
    "\n",
    "for i in tqdm(range(max_num_iters)):\n",
    "    hiddens, _ = model(inputs.unsqueeze(0))\n",
    "    hiddens = hiddens.squeeze(0)\n",
    "    preds = output(hiddens)\n",
    "    loss = F.mse_loss(preds, targets)\n",
    "\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    \n",
    "    scheduler.step(loss)\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(f'Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.34892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 168/5000 [00:20<02:07, 37.75it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.01501\n",
      "Loss: 0.00158\n",
      "Epoch  1484: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Loss: 0.00019\n",
      "Loss: 0.00012\n",
      "Loss: 0.00007\n",
      "Loss: 0.00004\n",
      "Loss: 0.00002\n",
      "Loss: 0.00001\n",
      "Epoch  4351: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Loss: 0.00000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a120d986e01f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "ds_size = 1024\n",
    "z_dim = 64\n",
    "hid_size = 1024\n",
    "dataset = torch.randn(ds_size, z_dim).to(DEVICE)\n",
    "max_num_iters = 5000\n",
    "bottleneck_dim = 16\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(z_dim, hid_size),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(hid_size),\n",
    "    \n",
    "    nn.Linear(hid_size, bottleneck_dim),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(bottleneck_dim),\n",
    "    \n",
    "    nn.Linear(bottleneck_dim, hid_size),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(hid_size),\n",
    "    \n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(hid_size),\n",
    "    nn.Linear(hid_size, z_dim)\n",
    ")\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, factor=0.2, patience=50, threshold=0.005, verbose=True)\n",
    "\n",
    "for i in range(max_num_iters):\n",
    "    preds = model(dataset)\n",
    "    loss = F.mse_loss(preds, dataset)\n",
    "\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    \n",
    "    scheduler.step(loss)\n",
    "\n",
    "    if i % 500 == 0:\n",
    "        print(f'Loss: {loss.item():.05f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

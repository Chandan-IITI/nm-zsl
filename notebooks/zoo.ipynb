{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024, 28, 28])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from typing import Tuple\n",
    "from torchvision.models.resnet import resnet18, resnet34, resnet50\n",
    "\n",
    "RESNET_FEAT_DIM = {18: 512, 34: 512, 50: 2048}\n",
    "RESNET_CONV_FEAT_DIM = {18: 256, 34: 256, 50: 1024}\n",
    "RESNET_TYPE_TO_CLS = {18: resnet18, 34: resnet34, 50: resnet50}\n",
    "\n",
    "z_dim = 512\n",
    "emb_dim = 512\n",
    "hid_dim = 1024\n",
    "resnet_type = 50\n",
    "\n",
    "class Reshape(nn.Module):\n",
    "    def __init__(self, target_shape: Tuple[int]):\n",
    "        super(Reshape, self).__init__()\n",
    "\n",
    "        self.target_shape = target_shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(*self.target_shape)\n",
    "    \n",
    "\n",
    "class ConvTransposeBNReLU(nn.Module):\n",
    "    def __init__(self, num_in_c: int, num_out_c: int, kernel_size: int, *conv_args, **conv_kwargs):\n",
    "        super(ConvTransposeBNReLU, self).__init__()\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "            nn.ConvTranspose2d(num_in_c, num_out_c, kernel_size, *conv_args, **conv_kwargs),\n",
    "            nn.BatchNorm2d(num_out_c),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "    \n",
    "class ResNetLastBlock(nn.Module):\n",
    "    def __init__(self, resnet_type: int, pretrained: bool, should_pool: bool=True):\n",
    "        super(ResNetLastBlock, self).__init__()\n",
    "\n",
    "        self.resnet = RESNET_TYPE_TO_CLS[resnet_type](pretrained=pretrained)\n",
    "        self.should_pool = should_pool\n",
    "\n",
    "        del self.resnet.conv1\n",
    "        del self.resnet.bn1\n",
    "        del self.resnet.relu\n",
    "        del self.resnet.maxpool\n",
    "        del self.resnet.layer1\n",
    "        del self.resnet.layer2\n",
    "        del self.resnet.layer3\n",
    "        del self.resnet.fc\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.resnet.layer4(x)\n",
    "\n",
    "        if self.should_pool:\n",
    "            x = self.resnet.avgpool(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "\n",
    "        return x\n",
    "\n",
    "encoder = ResNetLastBlock(50, True, False)\n",
    "decoder = nn.Sequential(\n",
    "    ConvTransposeBNReLU(z_dim + emb_dim, hid_dim, 5),\n",
    "    ConvTransposeBNReLU(hid_dim, hid_dim, 6),\n",
    "    nn.ConvTranspose2d(hid_dim, RESNET_CONV_FEAT_DIM[resnet_type], 6),\n",
    ")\n",
    "\n",
    "decoder(torch.rand(1, z_dim + emb_dim, 14, 14)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.7399, 0.7399, 0.7399],\n",
       "          [0.7399, 0.7399, 0.7399],\n",
       "          [0.7399, 0.7399, 0.7399]],\n",
       "\n",
       "         [[0.0919, 0.0919, 0.0919],\n",
       "          [0.0919, 0.0919, 0.0919],\n",
       "          [0.0919, 0.0919, 0.0919]]],\n",
       "\n",
       "\n",
       "        [[[0.5146, 0.5146, 0.5146],\n",
       "          [0.5146, 0.5146, 0.5146],\n",
       "          [0.5146, 0.5146, 0.5146]],\n",
       "\n",
       "         [[0.2894, 0.2894, 0.2894],\n",
       "          [0.2894, 0.2894, 0.2894],\n",
       "          [0.2894, 0.2894, 0.2894]]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class RepeatToSize(nn.Module):\n",
    "    def __init__(self, target_size: int):\n",
    "        super(RepeatToSize, self).__init__()\n",
    "        self.target_size = target_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert x.ndim == 4\n",
    "\n",
    "        if self.target_size == 1:\n",
    "            return x\n",
    "        else:\n",
    "            return x.repeat(1, 1, self.target_size, self.target_size)\n",
    "\n",
    "model = RepeatToSize(3)\n",
    "\n",
    "model(torch.rand(2, 2, 1, 1))\n",
    "# sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2048, 14, 14])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder(torch.rand(1, 1024, 28, 28)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('..')\n",
    "import torch\n",
    "import numpy as np\n",
    "from firelab.config import Config\n",
    "from src.models.lat_gm import LatGM\n",
    "# from src.dataloaders.load_data import load_data\n",
    "from src.dataloaders.cub import CUB\n",
    "\n",
    "# config = Config.load('../configs/lat_gm.yml')\n",
    "# config.all.hp.model.set('pretrained', True)\n",
    "# config.all.hp.model.set('num_classes', 200)\n",
    "# config = Config.load('../configs/base.yml')\n",
    "# ds_train, ds_test, attrs = load_data(Config({\n",
    "#  'num_reserved_classes': 0,\n",
    "#  'num_classes': 200,\n",
    "#  'num_classes_per_task': 20,\n",
    "#  'dir': '../data/CUB_200_2011',\n",
    "#  'num_tasks': 10,\n",
    "#  'name': 'CUB'}), embed_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Loading dataset]: 100%|██████████| 5994/5994 [03:15<00:00, 30.64it/s]\n",
      "[Loading dataset]: 100%|██████████| 5794/5794 [02:41<00:00, 35.99it/s]\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as T\n",
    "from src.dataloaders.cub import CUB\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.CenterCrop([448, 448]),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "ds_train = CUB('../data/CUB_200_2011', train=True, transform=transform)\n",
    "ds_test = CUB('../data/CUB_200_2011', train=False, transform=transform)\n",
    "\n",
    "# self.train_dataloader = DataLoader(ds_train, batch_size=self.config.hp.batch_size, shuffle=True)\n",
    "# self.val_dataloader = DataLoader(ds_test, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Extracting features]: 100%|██████████| 24/24 [00:50<00:00,  2.10s/it]\n",
      "[Extracting features]: 100%|██████████| 23/23 [00:49<00:00,  2.17s/it]\n"
     ]
    }
   ],
   "source": [
    "from src.dataloaders.utils import extract_resnet_features_for_dataset\n",
    "\n",
    "ds_train_feats = extract_resnet_features_for_dataset(ds_train, resnet_type=50, feat_level='conv', device='cuda', batch_size=256)\n",
    "ds_test_feats = extract_resnet_features_for_dataset(ds_test, resnet_type=50, feat_level='conv', device='cuda', batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/CUB_EMBEDDED/train_conv_feats_resnet50', ds_train_feats, allow_pickle=True)\n",
    "np.save('../data/CUB_EMBEDDED/test_conv_feats_resnet50', ds_test_feats, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data_train = np.load('../data/CUB_EMBEDDED/train_feats_resnet18.npy', allow_pickle=True)\n",
    "data_test = np.load('../data/CUB_EMBEDDED/test_feats_resnet18.npy', allow_pickle=True)\n",
    "\n",
    "classes_train = [d[1] for d in data_train]\n",
    "classes_test = [d[1] for d in data_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(classes_train, bins=200);\n",
    "plt.hist(classes_test, bins=200);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

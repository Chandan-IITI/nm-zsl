deeper_model:
    grid:
        head|after_fuse_transform_layers: ["{512}", "{256-512}", "{512-512}", "{512-512-512}"]
        optim|kwargs|lr: [0.0001, 0.0005, 0.001, 0.0025, 0.005]
        optim|kwargs|momentum: [0.0, 0.5, 0.9]
        head|num_prototypes: [1]
    baselines: []


generative_training:
    grid:
        # Required changes
        head|num_prototypes: [50]
        head|noise|std: [1.0]
        optim|kwargs|lr: [0.003]
        optim|kwargs|momentum: [0.0]
        generative_training|enabled: [true]

        # HPO search
        generative_training|loss_coef: [0.1, 1.0, 10.0]
        head|after_fuse_transform_layers: ["{256-512}", "{512-512-512}"]
        head|tanh_on_top: [True, False]
        generative_training|type: ["gdpp", "mmd"]
        generative_training|num_protos: [10, 25]

    baselines: [{head.after_fuse_transform_layers: "{256-512}"}]


autoencoding_loss:
    grid:
        # Required changes
        head|num_prototypes: [50]
        head|noise|std: [1.0]
        head|dae|enabled: [true]
        optim|kwargs|lr: [0.003]
        optim|kwargs|momentum: [0.0]

        # HPO search
        head|dae|loss_coef: [0.1, 1.0, 10.0]
        head|after_fuse_transform_layers: ["{256-512}", "{512-512-512}"]

    baselines: [{head.after_fuse_transform_layers: "{256-512}"}]


classifier_loss:
    grid:
        # Required changes
        head|num_prototypes: [50]
        head|noise|std: [1.0]
        head|dae|enabled: [true]
        optim|kwargs|lr: [0.003]
        optim|kwargs|momentum: [0.0]

        # HPO search
        head|dae|loss_coef: [0.1, 1.0, 10.0]
        head|after_fuse_transform_layers: ["{256-512}", "{512-512-512}"]

    baselines: [{head.after_fuse_transform_layers: "{256-512}"}]


attribute_dropout:
    grid:
        # Required changes
        head|num_prototypes: [50]
        head|noise|std: [1.0]
        head|dae|enabled: [true]
        optim|kwargs|lr: [0.003]
        optim|kwargs|momentum: [0.0]

        # HPO search
        head|dae|loss_coef: [0.1, 1.0, 10.0]
        head|after_fuse_transform_layers: ["{256-512}", "{512-512-512}"]

    baselines: [{head.after_fuse_transform_layers: "{256-512}"}]